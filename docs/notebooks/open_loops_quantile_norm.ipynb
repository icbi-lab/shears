{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c7a823-3a4a-449d-a08f-bd732a768d08",
   "metadata": {},
   "source": [
    "# Thoughts on quantile normalization\n",
    "\n",
    "Quantile normalization is a method used to make the distribution of gene expression levels the same across all samples, making them comparable.\n",
    "\n",
    "1. **Rank the genes** in each sample from lowest to highest expression.\n",
    "2. **Calculate the average** expression value for genes that share the same rank across all samples.\n",
    "3. **Replace the original values** with these average values for each corresponding rank.\n",
    "4. **Reorder the genes** in each sample back to their original order.\n",
    "\n",
    "`shears` takes as input a single cell matrix and a bulk matrix with raw counts that need to be normalized. These input matrices are subsetted for highly variable genes (hvg=2000) computed on the single cell data to remove background noise.\n",
    "\n",
    "For quantile normalisation `scissor` first [combines](https://github.com/sunduanchen/Scissor/blob/311560a1f160f665917e7da0fcf289914ee99773/R/Scissor.R#L78-L79) the single cell and bulk data before spliting it back after the transformation ([see](#3a-quantile-normalize-scissor-approach)). To me, this does not make much sense, as I would expect the bulk samples to be more similar to one another than to the individual single cells using hvgs. Especially for large single cell matrices (>1M cells) - like the CRC-atlas - I would expect `sklearn.preprocessing.quantile_transform(X)` with the default of `n_quantiles=1000` to put all bulk patients in the same quantile.\n",
    "\n",
    "The `class-specific` strategy is an alternative approach that first splits the data by sample class-labels before performing quantile normalization independently on each split [PMID: 32968196](https://www.nature.com/articles/s41598-020-72664-6). The `discrete` strategy takes the `Class-specific` approach further, and also accounts for the batch factor. Each split (by class and batch) are then quantile-normalized separately, and then recombined into one dataset.\n",
    "\n",
    "For the CRC-atlas, I would expect the biggest technical batch effects between platforms/datasets. When subsetting for hvgs, enriched datasets will have low counts for the \"missing\" cells, while bulk samples will have counts across all cell types. `class-specific` effects could be across cell types. (what resolution? fine/coarse). Within a given cell type I am not sure if the same genes have the highest counts across platforms/datasets, which would put them into the same quantile regardless of the absolute value (i.e smartseq samples will have much higher counts than 10x samples, but is the relative distribution from low to high within cell types the same?)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058200d-696a-44d4-807f-fe083803079d",
   "metadata": {},
   "source": [
    "### 1. Load data\n",
    "\n",
    "1. **CRC single cell atlas:** sc dataset\n",
    "2. **TCGA-COAD/READ cohort:** bulk dataset with clinical annotations\n",
    "3. **AC-ICAM cohort:** bulk dataset with more accurate clinical annotations; [PMID: 37202560](https://www.nature.com/articles/s41591-023-02324-5) 348 patients with primary colon cancer. This is the recently published follow up to the TCGA-COAD/READ cohort that was mostly used for colorectal cancer up to this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94e63e5-fb4b-41dd-b217-690f21baf809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import anndata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import shears as sh\n",
    "from nxfvars import nxfvars\n",
    "from threadpoolctl import threadpool_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6341867e-97cb-4eed-81b8-46e4da0400ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus = nxfvars.get(\"cpus\", 16)\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = str(cpus)\n",
    "threadpool_limits(cpus)\n",
    "sc.settings.n_jobs = cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6393aeb4-efdf-4f7e-a0af-1988bf3ea0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_path = nxfvars.get(\n",
    "    \"adata_path\",\n",
    "    \"/data/scratch/marteau/results_old/crc-atlas/uncompressed_h5ad/core_atlas-adata.h5ad\",\n",
    ")\n",
    "AC_ICAM_bulk_path = nxfvars.get(\n",
    "    \"AC_ICAM_bulk_path\",\n",
    "    \"/data/scratch/marteau/results/crc-atlas/downstream_analyses/shears/AC_ICAM_bulk-adata.h5ad\",\n",
    ")\n",
    "TCGA_bulk_path = nxfvars.get(\n",
    "    \"TCGA_bulk_path\",\n",
    "    \"/data/scratch/marteau/results/crc-atlas/downstream_analyses/shears/TCGA_bulk_counts-adata.h5ad\",\n",
    ")\n",
    "artifact_dir = nxfvars.get(\n",
    "    \"artifact_dir\",\n",
    "    \"/data/scratch/marteau/results/crc-atlas/downstream_analyses/shears/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "748ca8f5-c029-4dfc-89e4-655b936019f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The adatas all contain raw counts data\n",
    "adata_sc = sc.read_h5ad(adata_path)\n",
    "adata_icam = sc.read_h5ad(AC_ICAM_bulk_path)\n",
    "adata_tcga = sc.read_h5ad(TCGA_bulk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d964156-bb52-422f-992c-1e9349ad9161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4264929, 28476)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c748772-34ab-4d62-a943-d0557b716cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622, 60483)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_tcga.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272ea271-360b-45b3-94c2-ab80ac7b223b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348, 58395)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_icam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8027918a-298f-4df9-85fd-13688c874249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for primary tumor samples -> same sample type as bulk\n",
    "adata_sc = adata_sc[adata_sc.obs[\"sample_type\"].isin([\"tumor\"])].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78011a7e-e613-4fd6-8929-fade6bdc96b4",
   "metadata": {},
   "source": [
    "Impact of further subsetting? For example \n",
    "\n",
    "* removing sorted datasets\n",
    "* keep only core/border samples\n",
    "* keep only MSS/MSI samples\n",
    "\n",
    "When to subset? before hvg calculation or after?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f038a9cc-2ea1-4aaf-a58b-9c81ad50e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace normalized counts and remove duplicate layer\n",
    "adata_sc.X = adata_sc.layers[\"counts\"].copy()\n",
    "del adata_sc.layers[\"counts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af493f-dc89-43e7-bc99-33dec39fa7a5",
   "metadata": {},
   "source": [
    "### 2. Subset for highly variable genes\n",
    "\n",
    "Why 2000 hvgs? What is the ideal number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aac0f1a6-e797-4a70-84aa-9b31229d58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Filter raw bulk matrices for informative genes\n",
    "sc.pp.filter_genes(adata_icam, min_counts=20)\n",
    "sc.pp.filter_genes(adata_icam, min_cells=20)  # Expression > 20 counts in min 20 patients\n",
    "\n",
    "sc.pp.filter_genes(adata_tcga, min_counts=20)\n",
    "sc.pp.filter_genes(adata_tcga, min_cells=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0537c112-2c8e-4407-b598-97b01e44ffe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622, 46585)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_tcga.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4e3b91a-b7cf-4b82-a033-d10c31ae297d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348, 37140)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_icam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a095ff43-f493-4bf2-b766-dc1f8ca6b1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1846319, 24810)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get common genes across cohorts (ideally using ensembl ids)\n",
    "adata_hvg = adata_sc[\n",
    "    :,\n",
    "    (adata_sc.var_names.isin(adata_tcga.var_names))\n",
    "    & adata_sc.var_names.isin(adata_icam.var_names),\n",
    "].copy()\n",
    "adata_hvg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97cab098-2a0c-4218-a347-35a796afb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find a meaningfull signal in the bulk sample I would expect a minimum number of cells to be present\n",
    "sc.pp.filter_genes(adata_hvg, min_cells=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70901e5c-69b1-4ead-88b0-90b88822bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Remove few samples in atlas that produce \"ValueError: b'There are other near singularities as well.\" -> Use a loop calling sc.pp.highly_variable_genes on individual samples to get a list of failling ones\n",
    "hvg = sc.pp.highly_variable_genes(\n",
    "    adata_hvg[\n",
    "        ~adata_hvg.obs[\"sample_id\"].isin(\n",
    "            [\n",
    "                \"Joanito_2022_SG1.MUX9380\",\n",
    "                \"Khaliq_2022.T_CAC5\",\n",
    "                \"Li_2017.CRC03_tumor\",\n",
    "                \"Li_2017.CRC06_tumor\",\n",
    "                \"Li_2017.CRC08_tumor\",\n",
    "                \"Pelka_2021_10Xv2.C138_T_0_0_0_c2_v2\",\n",
    "                \"Pelka_2021_10Xv2_CD45Pos.C138_T_0_0_1_c1_v2\",\n",
    "                \"Pelka_2021_10Xv2_CD45Pos.C138_T_0_0_1_c2_v2\",\n",
    "                \"Wu_2022_CD45Pos.P1_Colon_T\",\n",
    "                \"Wu_2022_CD45Pos.P15_Colon_T\",\n",
    "                \"Wu_2022_CD45Pos.P20_Colon_T\",\n",
    "                \"Wu_2024_CD66bPos.COAD2_T\",\n",
    "                \"Wu_2024_CD66bPos.COAD3_T\",\n",
    "                \"Wu_2024_CD66bPos.COAD14_T\",\n",
    "                \"Wu_2024_CD66bPos.COAD15_T\",\n",
    "                \"Wu_2024_CD66bPos.COAD16_T\",\n",
    "                \"Wu_2024_CD66bPos.COAD19_T\",\n",
    "                \"Wu_2024_CD66bPos.COAD20_T\",\n",
    "                \"Zhang_2020_10X_CD45Pos.T_P0123\",\n",
    "                \"Zhang_2020_10X_CD45Pos.T_P0305\",\n",
    "                \"deVries_2023_LUMC.HTO1\",\n",
    "                \"deVries_2023_LUMC.HTO6\",\n",
    "            ]\n",
    "        )\n",
    "    ],\n",
    "    n_top_genes=2000,\n",
    "    subset=False,\n",
    "    flavor=\"seurat_v3\",\n",
    "    # layer=\"counts\",\n",
    "    batch_key=\"sample_id\",\n",
    "    span=0.3,  # does not work with default span=0.3 for above samples (probably not enough cells)\n",
    "    inplace=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b91c34b-e82c-4347-aaf3-64fa38cac276",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvg_dict = hvg[\"highly_variable\"].to_dict()\n",
    "adata_sc.var[\"highly_variable\"] = adata_sc.var_names.map(hvg_dict).fillna(value=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48661a72-96c3-4c54-988b-adef33109cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "protein_coding                    1541\n",
       "lncRNA                             200\n",
       "IG_V_gene                          104\n",
       "TR_V_gene                           81\n",
       "IG_V_pseudogene                     18\n",
       "IG_C_gene                           12\n",
       "TR_J_gene                           10\n",
       "miRNA                               10\n",
       "transcribed_unitary_pseudogene       7\n",
       "IG_J_gene                            4\n",
       "IG_C_pseudogene                      3\n",
       "TR_C_gene                            3\n",
       "TR_V_pseudogene                      3\n",
       "Mt_tRNA                              2\n",
       "IG_J_pseudogene                      1\n",
       "artifact                             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can have a look at the hvg classes -> It would be possible to exclude classes\n",
    "adata_sc[:, adata_sc.var[\"highly_variable\"]].var[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fd0fe28-17c6-41e2-9cf0-734795820002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for hvgs\n",
    "adata_sc = adata_sc[:, adata_sc.var[\"highly_variable\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "566ca152-7a2d-4ae8-aeee-c67269ad154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset bulk for atlas hvg\n",
    "adata_icam = adata_icam[:, adata_icam.var_names.isin(adata_sc.var_names)].copy()\n",
    "# Subset bulk for atlas hvg\n",
    "adata_tcga = adata_tcga[:, adata_tcga.var_names.isin(adata_sc.var_names)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "636c29d2-0557-4259-b0cc-e3b41759bbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1846319, 2000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ef8420e-c31d-497c-b594-1192fa1118ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348, 2000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_icam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0119ea3-6f1a-4855-85d4-fe9139eeecf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622, 2000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_tcga.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923973a4-a644-4c67-865e-8d7fdabfb0e0",
   "metadata": {},
   "source": [
    "### 3. Quantile normalize\n",
    "How to handle already normalized counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a15b1e08-5f2d-4be3-b4aa-8360474b3601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "from anndata import AnnData\n",
    "\n",
    "\n",
    "def quantile_norm(adata: AnnData, *, layer=None, key_added=\"quantile_norm\", **kwargs):\n",
    "    \"\"\"Perform quantile normalization on AnnData object\n",
    "\n",
    "    Stores the normalized data in a new layer with the key `key_added`.\n",
    "    \"\"\"\n",
    "    X = adata.X if layer is None else adata.layers[layer]\n",
    "    adata.layers[key_added] = sklearn.preprocessing.quantile_transform(X, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6f13657-83f2-4ba4-8919-15edfbab274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the bulk data has less then 1000 patients using the default n_quantiles=1000 will put each patient in his own quantile. Not sure I want this. Id rather have similar patients in the same quantiles\n",
    "quantile_norm(adata_icam, n_quantiles=100)\n",
    "quantile_norm(adata_tcga, n_quantiles=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2dbdc97-56c3-4c19-ae04-86c495beb415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_277810/1361028706.py:11: ImplicitModificationWarning: Setting element `.layers['quantile_norm']` of view, initializing view as actual.\n",
      "  adata.layers[key_added] = sklearn.preprocessing.quantile_transform(X, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Quantile normalize by batch_key (dataset in this case)\n",
    "adata_dict = {\n",
    "    dataset: adata_sc[adata_sc.obs[\"dataset\"] == dataset]\n",
    "    for dataset in adata_sc.obs[\"dataset\"].unique()\n",
    "}\n",
    "\n",
    "# For the class-specific approach could make new label with dataset/platform + cell_type -> Not sure what a min input number should be for quantile norm\n",
    "batch_key = \"dataset\"\n",
    "\n",
    "for dataset in adata_sc.obs[\"dataset\"].unique():\n",
    "    quantile_norm(\n",
    "        adata_dict[dataset],\n",
    "        n_quantiles=(\n",
    "            100\n",
    "            if adata_sc[adata_sc.obs[batch_key] == dataset].shape[0] < 1000\n",
    "            else 1000\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da026d28-a799-4bdb-8c6d-5fafbab9fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine back together\n",
    "adata_sc = anndata.concat(adata_dict, index_unique=\"-\", join=\"outer\", fill_value=0)\n",
    "adata_sc.obs_names = adata_sc.obs_names.str.rsplit(\"-\", n=1).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "205b7ff0-b60d-42a5-ab4a-e4b088f9575a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1846319, 2000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_sc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd32ce-ff14-430b-a9c8-f9744a5c0a94",
   "metadata": {},
   "source": [
    "#### 3a. Quantile normalize (scissor approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb07dc9b-d13e-47f4-b494-8e0b51b290fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append bulk to sc data\n",
    "adata = anndata.concat(\n",
    "    [adata_sc, adata_icam], index_unique=\"-\", join=\"outer\", fill_value=0\n",
    ")\n",
    "adata.obs_names = adata.obs_names.str.rsplit(\"-\", n=1).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474f4f8-252c-4dae-af52-d3d024121bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh.pp.quantile_norm(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531849c-a7d8-42eb-a0e8-b634c48a62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_icam = adata[adata.obs_names.isin(adata_icam.obs_names)].copy()\n",
    "adata_icam.obs = adata_icam.obs.dropna(axis=1, how=\"all\")\n",
    "adata_icam.layers[\"quantile_norm\"] = adata_icam.layers[\"quantile_norm\"].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7479f7a5-2664-42a6-a447-fb12cb84d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_sc = adata[adata.obs_names.isin(adata_sc.obs_names)].copy()\n",
    "adata_sc.obs = adata_sc.obs.dropna(axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22fc22b-558e-4523-a62b-c4f599a5361a",
   "metadata": {},
   "source": [
    "### 4. Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7390dab1-30ab-4814-95aa-45b735b955f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_sc.write(f\"{artifact_dir}/core_atlas_hvg_2000-adata.h5ad\")\n",
    "adata_tcga.write(f\"{artifact_dir}/TCGA_bulk_hvg_2000-adata.h5ad\")\n",
    "adata_icam.write(f\"{artifact_dir}/AC_ICAM_bulk_hvg_2000-adata.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crc-analyses kernel",
   "language": "python",
   "name": "crc-analyses"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
